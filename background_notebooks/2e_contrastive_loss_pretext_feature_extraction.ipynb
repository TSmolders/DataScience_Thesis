{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM: Extract features on labeled data using the pretrained EEGNet\n",
    "across subject pretext task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# prevent extensive logging\n",
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading epoch data & participant data of labeled sample\n",
    "These dataframes have been filtered and stored in a previous project. See https://github.com/TSmolders/Internship_EEG for original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 12)\n",
      "diagnosis\n",
      "ADHD       45\n",
      "HEALTHY    45\n",
      "MDD        45\n",
      "OCD        45\n",
      "SMC        45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_participants = pd.read_pickle(r'D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TDBRAIN_participants_V2_data\\df_participants.pkl')\n",
    "sample_df = pd.read_pickle(r'D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TD-BRAIN_extracted_features\\df_selected_stat_features.pkl')\n",
    "sample_ids = sample_df['ID'].unique() # obtain unique IDs from subsampled dataframe containing epoched features\n",
    "df_sample = df_participants[df_participants['participants_ID'].isin(sample_ids)] # filter participants dataframe to only include subsampled IDs\n",
    "df_sample = df_sample[df_sample['sessID'] == 1] # filter first session\n",
    "print(df_sample.shape)\n",
    "print(df_sample['diagnosis'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for loading the epoched EEG data\n",
    "def get_filepath(epoch_dir, participant_ids):\n",
    "    \"\"\"\n",
    "    Function to get the filepath of the epoched EEG recording\n",
    "    :param epoch_dir: directory containing the epoched EEG recordings\n",
    "    :param ID: list of participant IDs to include\n",
    "    \"\"\"\n",
    "    filepaths = []\n",
    "    for subdir, dirs, files in os.walk(epoch_dir):\n",
    "        for file in files:\n",
    "            if any(participant_id in file for participant_id in participant_ids):\n",
    "                filepaths.append(os.path.join(subdir, file))\n",
    "    return filepaths\n",
    "\n",
    "class EpochDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, participant_ids, epoch_dir):\n",
    "        self.filepaths = get_filepath(epoch_dir, participant_ids)\n",
    "        self.participant_ids = participant_ids\n",
    "        self.epochs = []\n",
    "        self.participant_ids = []\n",
    "        self._load_data()\n",
    "        print(f\"Number of epochs: {self.epochs.shape[0]}\")\n",
    "        print(f\"Number of participants: {len(self.participant_ids)}\")\n",
    "\n",
    "    def _load_data(self):\n",
    "        all_epochs = []\n",
    "        for filepath in self.filepaths:\n",
    "            epochs = torch.load(filepath)\n",
    "            # get participant ID from filepath to make sure the participant ID is correct\n",
    "            participant_id = filepath.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "            all_epochs.append(epochs)\n",
    "            self.participant_ids.extend([participant_id]*epochs.shape[0])\n",
    "        self.epochs = np.concatenate(all_epochs, axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.epochs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        epoch = self.epochs[idx]\n",
    "        participant_id = self.participant_ids[idx]\n",
    "        return torch.tensor(epoch, dtype=torch.float32), participant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 2688\n",
      "Number of participants: 2688\n",
      "2688\n",
      "torch.Size([26, 1244])\n",
      "sub-87964717\n",
      "sub-87964717\n"
     ]
    }
   ],
   "source": [
    "# load the epochs into a dataset\n",
    "participant_ids = df_sample['participants_ID'].tolist()\n",
    "dataset = EpochDataset(participant_ids, r\"D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TDBRAIN-dataset-derivatives\\thesis_epoched_data\\EC\")\n",
    "print(len(dataset))\n",
    "print(dataset[0][0].shape)\n",
    "print(dataset[0][1])\n",
    "print(dataset[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfering pretrained weights & extracting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(pretrained_weights, pretext_model):\n",
    "    \"\"\"\n",
    "    Function to transfer the pretrained weights to the pretext model\n",
    "    param: pretrained_weights: the weights to transfer in a dictionary\n",
    "    param: pretext_model: the model to transfer the weights to\n",
    "    \"\"\"\n",
    "    pretrained_model = pretext_model\n",
    "    modified_keys = {}\n",
    "    for k, v in pretrained_weights.items():\n",
    "        decomposed_key = k.split('.')\n",
    "        if decomposed_key[0] == 'EEGNet' or decomposed_key[0] == 'ShallowNet': # remove the first part of each key to match the model's keys\n",
    "            pretrained_key = '.'.join(decomposed_key[1:])\n",
    "            modified_keys[pretrained_key] = v\n",
    "\n",
    "            \n",
    "    pretrained_model.load_state_dict(modified_keys)\n",
    "        \n",
    "    return pretrained_model\n",
    "\n",
    "def extract_features(pretrained_model, data, pretext_task, df_sample, to_disk=False):\n",
    "    \"\"\"\n",
    "    Function to extract features from the pretrained model\n",
    "    param: pretrained_model: the model to extract features from\n",
    "    param: data: the dataset containing the epochs to extract features from\n",
    "    param: pretext_task: a string indicating the specific pretext task to save the features as\n",
    "    param: df_sample: the dataframe containing the sampled participant IDs and their corresponding diagnosis\n",
    "    param: to_disk: boolean to save the features to disk\n",
    "    \"\"\"\n",
    "    dataloader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=False)\n",
    "    pretrained_model.eval()\n",
    "    features_list = []\n",
    "    participant_ids = []\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for batch in dataloader:\n",
    "            epoch, participant_id = batch  # Remove the batch dimension\n",
    "            epoch = epoch.unsqueeze(0)  # Add dimension\n",
    "            # print(epoch.shape)\n",
    "            features = pretrained_model(epoch)  # Extract features\n",
    "            features = features.squeeze(0)\n",
    "            features = features.numpy()\n",
    "            features_list.append(features)\n",
    "            participant_ids.append(participant_id[0])\n",
    "\n",
    "    \n",
    "    features_df = pd.DataFrame(features_list) # store as dataframe\n",
    "    features_df['ID'] = participant_ids # add participant IDs to the dataframe\n",
    "    # map the diagnosis values from df_sample to the dataframe based on participant IDs\n",
    "    features_df['diagnosis'] = features_df['ID'].map(df_sample.set_index('participants_ID')['diagnosis'])\n",
    "    \n",
    "    print(f'{features_df.shape = }')\n",
    "    display(features_df.head(3))\n",
    "\n",
    "\n",
    "    if to_disk:\n",
    "        features_df.to_pickle(f'D:/Documents/Master_Data_Science/Thesis/thesis_code/DataScience_Thesis/data/SSL_features/df_{pretext_task}_features.pkl')\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "def evaluate_features(features_df):\n",
    "    \"\"\"\n",
    "    Function to quickly evaluate the extracted features. Doesn't stratify/group data splitting! \n",
    "    \"\"\"\n",
    "    groups = features_df['ID']\n",
    "    X = features_df.drop(['ID', 'diagnosis'], axis=1)\n",
    "    y = features_df['diagnosis']\n",
    "\n",
    "    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "    # Get the train and test indices\n",
    "    for train_index, test_index in sgkf.split(X, y, groups):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        break  # Only use the first split\n",
    "\n",
    "    # quick SVM model\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('quick SVM model')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f1_score(y_test, y_pred, average='macro'))\n",
    "    print()\n",
    "\n",
    "    # quick random forest model\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('quick random forest model')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    return\n",
    "\n",
    "def get_ssl_features(\n",
    "        pretext_task,\n",
    "        data,\n",
    "        df_sample,\n",
    "        num_extracted_features=100,\n",
    "        eval=True,\n",
    "        to_disk=True,\n",
    "        pretext_model='EEGNet',\n",
    "        weights_dir=r'D:\\Documents\\Master_Data_Science\\Thesis\\thesis_code\\DataScience_Thesis\\data\\pretext_model_weights'\n",
    "                     ):\n",
    "    \"\"\"\n",
    "    Obtains SSL features from the weights trained by the pretext model.\n",
    "    param: pretext_task: a string indicating the specific pretext task to load the weights from and save the features as\n",
    "    param: data: the dataset containing the epochs to extract features from\n",
    "    param: df_sample: the dataframe containing the sampled participant IDs and their corresponding diagnosis\n",
    "    param: num_extracted_features: the number of features to extract\n",
    "    param: eval: boolean to evaluate the features\n",
    "    param: to_disk: boolean to save the features to disk\n",
    "    param: pretext_model: the model to extract features from\n",
    "    param: weights_dir: the directory containing the weights of the pretext model\n",
    "    \"\"\"\n",
    "    # Need to define model class here to avoid issues with different number of extracted features\n",
    "    # create Conv2d with max norm constraint\n",
    "    class Conv2dWithConstraint(nn.Conv2d):\n",
    "        def __init__(self, *args, max_norm: int = 1, **kwargs):\n",
    "            self.max_norm = max_norm\n",
    "            super(Conv2dWithConstraint, self).__init__(*args, **kwargs)\n",
    "\n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            self.weight.data = torch.renorm(self.weight.data, p=2, dim=0, maxnorm=self.max_norm)\n",
    "            return super(Conv2dWithConstraint, self).forward(x)\n",
    "        \n",
    "    class EEGNet(nn.Module):\n",
    "        \"\"\"\n",
    "        Code taken and adjusted from pytorch implementation of EEGNet\n",
    "        url: https://github.com/torcheeg/torcheeg/blob/v1.1.0/torcheeg/models/cnn/eegnet.py#L5\n",
    "        \"\"\"\n",
    "        def __init__(self,\n",
    "                    chunk_size: int = 1244, # number of data points in each EEG chunk\n",
    "                    num_electrodes: int = 26, # number of EEG electrodes\n",
    "                    F1: int = 8, # number of filters in first convolutional layer\n",
    "                    F2: int = 16, # number of filters in second convolutional layer\n",
    "                    D: int = 2, # depth multiplier\n",
    "                    num_extracted_features: int = num_extracted_features, # number of features to extract\n",
    "                    kernel_1: int = 64, # the filter size of block 1 (half of sfreq (125 Hz))\n",
    "                    kernel_2: int = 16, # the filter size of block 2 (one eight of sfreq (500 Hz))\n",
    "                    dropout: float = 0.25): # dropout rate\n",
    "            super(EEGNet, self).__init__()\n",
    "            self.F1 = F1\n",
    "            self.F2 = F2\n",
    "            self.D = D\n",
    "            self.chunk_size = chunk_size\n",
    "            self.num_extracted_features = num_extracted_features\n",
    "            self.num_electrodes = num_electrodes\n",
    "            self.kernel_1 = kernel_1\n",
    "            self.kernel_2 = kernel_2\n",
    "            self.dropout = dropout\n",
    "\n",
    "            self.block1 = nn.Sequential(\n",
    "                nn.Conv2d(1, self.F1, (1, self.kernel_1), stride=1, padding=(0, self.kernel_1 // 2), bias=False),\n",
    "                nn.BatchNorm2d(self.F1, momentum=0.01, affine=True, eps=1e-3),\n",
    "                Conv2dWithConstraint(self.F1,\n",
    "                                    self.F1 * self.D, (self.num_electrodes, 1),\n",
    "                                    max_norm=1,\n",
    "                                    stride=1,\n",
    "                                    padding=(0, 0),\n",
    "                                    groups=self.F1,\n",
    "                                    bias=False), nn.BatchNorm2d(self.F1 * self.D, momentum=0.01, affine=True, eps=1e-3),\n",
    "                nn.ELU(), nn.AvgPool2d((1, 4), stride=4), nn.Dropout(p=dropout))\n",
    "\n",
    "            self.block2 = nn.Sequential(\n",
    "                nn.Conv2d(self.F1 * self.D,\n",
    "                        self.F1 * self.D, (1, self.kernel_2),\n",
    "                        stride=1,\n",
    "                        padding=(0, self.kernel_2 // 2),\n",
    "                        bias=False,\n",
    "                        groups=self.F1 * self.D),\n",
    "                nn.Conv2d(self.F1 * self.D, self.F2, 1, padding=(0, 0), groups=1, bias=False, stride=1),\n",
    "                nn.BatchNorm2d(self.F2, momentum=0.01, affine=True, eps=1e-3), nn.ELU(), nn.AvgPool2d((1, 8), stride=8),\n",
    "                nn.Dropout(p=dropout))\n",
    "\n",
    "            self.lin = nn.Linear(self.feature_dim(), num_extracted_features, bias=False)\n",
    "\n",
    "\n",
    "        def feature_dim(self):\n",
    "            # function to calculate the number of features after the convolutional blocks\n",
    "            with torch.no_grad():\n",
    "                mock_eeg = torch.zeros(1, 1, self.num_electrodes, self.chunk_size)\n",
    "\n",
    "                mock_eeg = self.block1(mock_eeg)\n",
    "                mock_eeg = self.block2(mock_eeg)\n",
    "\n",
    "            return self.F2 * mock_eeg.shape[3]\n",
    "\n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            x = self.block1(x)\n",
    "            x = self.block2(x)\n",
    "            x = x.flatten(start_dim=1)\n",
    "            x = self.lin(x)\n",
    "            return x\n",
    "    \n",
    "    class ShallowNet(nn.Module):\n",
    "        \"\"\"\n",
    "        Pytorch implementation of the ShallowNet Encoder.\n",
    "        Code taken and adjusted from:\n",
    "        https://github.com/MedMaxLab/selfEEG/blob/024402ba4bde95051d86ab2524cc71105bfd5c25/selfeeg/models/zoo.py#L693\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self,\n",
    "                    samples=1244,\n",
    "                    chans=26, # number of EEG channels\n",
    "                    F=40, # number of output filters in the temporal convolution layer\n",
    "                    K1=25, # length of the temporal convolutional layer\n",
    "                    pool=75, # temporal pooling kernel size\n",
    "                    dropout=0.2, # dropout probability\n",
    "                    num_extracted_features=num_extracted_features # number of features to extract\n",
    "                    ):\n",
    "\n",
    "            super(ShallowNet, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, F, (1, K1), stride=(1, 1))\n",
    "            self.conv2 = nn.Conv2d(F, F, (chans, 1), stride=(1, 1))\n",
    "            self.batch1 = nn.BatchNorm2d(F)\n",
    "            self.pool2 = nn.AvgPool2d((1, pool), stride=(1, 15))\n",
    "            self.flatten2 = nn.Flatten()\n",
    "            self.drop1 = nn.Dropout(dropout)\n",
    "            self.lin = nn.Linear(\n",
    "                F * ((samples - K1 + 1 - pool) // 15 + 1), num_extracted_features\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.batch1(x)\n",
    "            x = torch.square(x)\n",
    "            x = self.pool2(x)\n",
    "            x = torch.log(torch.clamp(x, 1e-7, 10000))\n",
    "            x = self.flatten2(x)\n",
    "            x = self.drop1(x)\n",
    "            x = self.lin(x)\n",
    "\n",
    "            return x\n",
    "    \n",
    "    if pretext_model == 'EEGNet':\n",
    "        pretext_model = EEGNet()\n",
    "    if pretext_model == 'ShallowNet':\n",
    "        pretext_model = ShallowNet()\n",
    "        \n",
    "    pretrained_weights = torch.load(f'{weights_dir}\\{pretext_task}_weights.pt')\n",
    "    pretrained_model = transfer_weights(pretrained_weights, pretext_model)\n",
    "    features_df = extract_features(pretrained_model, data, pretext_task, df_sample=df_sample, to_disk=to_disk)\n",
    "    if eval:\n",
    "        evaluate_features(features_df)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomly initialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_df.shape = (2688, 102)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.025231</td>\n",
       "      <td>0.558265</td>\n",
       "      <td>0.386430</td>\n",
       "      <td>-0.427448</td>\n",
       "      <td>-0.195549</td>\n",
       "      <td>-0.385354</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.385304</td>\n",
       "      <td>0.106288</td>\n",
       "      <td>0.573986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261263</td>\n",
       "      <td>0.668248</td>\n",
       "      <td>-0.518208</td>\n",
       "      <td>0.242272</td>\n",
       "      <td>0.186938</td>\n",
       "      <td>0.214983</td>\n",
       "      <td>0.118263</td>\n",
       "      <td>-0.321973</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.111984</td>\n",
       "      <td>0.977839</td>\n",
       "      <td>0.131731</td>\n",
       "      <td>-0.051678</td>\n",
       "      <td>-0.290045</td>\n",
       "      <td>-0.434035</td>\n",
       "      <td>0.237411</td>\n",
       "      <td>-0.101681</td>\n",
       "      <td>-0.275212</td>\n",
       "      <td>0.762277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520117</td>\n",
       "      <td>0.624576</td>\n",
       "      <td>-0.485054</td>\n",
       "      <td>0.251544</td>\n",
       "      <td>-0.037080</td>\n",
       "      <td>-0.125105</td>\n",
       "      <td>-0.325259</td>\n",
       "      <td>-0.672581</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033515</td>\n",
       "      <td>0.690026</td>\n",
       "      <td>-0.037421</td>\n",
       "      <td>-0.427968</td>\n",
       "      <td>-0.044509</td>\n",
       "      <td>-0.273484</td>\n",
       "      <td>0.223849</td>\n",
       "      <td>0.226518</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.772421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178688</td>\n",
       "      <td>0.269243</td>\n",
       "      <td>-0.326347</td>\n",
       "      <td>-0.047144</td>\n",
       "      <td>-0.056313</td>\n",
       "      <td>0.331418</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>-0.459115</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.025231  0.558265  0.386430 -0.427448 -0.195549 -0.385354  0.035971   \n",
       "1 -0.111984  0.977839  0.131731 -0.051678 -0.290045 -0.434035  0.237411   \n",
       "2 -0.033515  0.690026 -0.037421 -0.427968 -0.044509 -0.273484  0.223849   \n",
       "\n",
       "          7         8         9  ...        92        93        94        95  \\\n",
       "0  0.385304  0.106288  0.573986  ...  0.261263  0.668248 -0.518208  0.242272   \n",
       "1 -0.101681 -0.275212  0.762277  ...  0.520117  0.624576 -0.485054  0.251544   \n",
       "2  0.226518  0.001657  0.772421  ...  0.178688  0.269243 -0.326347 -0.047144   \n",
       "\n",
       "         96        97        98        99            ID  diagnosis  \n",
       "0  0.186938  0.214983  0.118263 -0.321973  sub-87964717        SMC  \n",
       "1 -0.037080 -0.125105 -0.325259 -0.672581  sub-87964717        SMC  \n",
       "2 -0.056313  0.331418  0.099657 -0.459115  sub-87964717        SMC  \n",
       "\n",
       "[3 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick SVM model\n",
      "[[58 17  5 16 12]\n",
      " [15 36  9 32 16]\n",
      " [13 29 24 21 21]\n",
      " [ 0 27 21 33 27]\n",
      " [ 3  4 15 26 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADHD       0.65      0.54      0.59       108\n",
      "     HEALTHY       0.32      0.33      0.33       108\n",
      "         MDD       0.32      0.22      0.26       108\n",
      "         OCD       0.26      0.31      0.28       108\n",
      "         SMC       0.44      0.56      0.49       108\n",
      "\n",
      "    accuracy                           0.39       540\n",
      "   macro avg       0.40      0.39      0.39       540\n",
      "weighted avg       0.40      0.39      0.39       540\n",
      "\n",
      "0.3899649803774411\n",
      "\n",
      "quick random forest model\n",
      "[[62 14 14 10  8]\n",
      " [18 34 20 22 14]\n",
      " [22 28 26 15 17]\n",
      " [10 24 28 18 28]\n",
      " [ 3 23 15 19 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADHD       0.54      0.57      0.56       108\n",
      "     HEALTHY       0.28      0.31      0.29       108\n",
      "         MDD       0.25      0.24      0.25       108\n",
      "         OCD       0.21      0.17      0.19       108\n",
      "         SMC       0.42      0.44      0.43       108\n",
      "\n",
      "    accuracy                           0.35       540\n",
      "   macro avg       0.34      0.35      0.34       540\n",
      "weighted avg       0.34      0.35      0.34       540\n",
      "\n",
      "0.34297297544088395\n"
     ]
    }
   ],
   "source": [
    "features_df = extract_features(EEGNet(), dataset, df_sample=df_sample, pretext_task='random', to_disk=False)\n",
    "evaluate_features(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretext model with default parameters (0.25 dropout, 0 weight decay, binary cross entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_df.shape = (2688, 102)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.427210</td>\n",
       "      <td>-0.320270</td>\n",
       "      <td>-0.282973</td>\n",
       "      <td>-0.141028</td>\n",
       "      <td>0.262942</td>\n",
       "      <td>0.065654</td>\n",
       "      <td>0.073298</td>\n",
       "      <td>0.137498</td>\n",
       "      <td>0.296130</td>\n",
       "      <td>-0.075196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029153</td>\n",
       "      <td>0.157873</td>\n",
       "      <td>0.154806</td>\n",
       "      <td>0.033090</td>\n",
       "      <td>0.054093</td>\n",
       "      <td>-0.021883</td>\n",
       "      <td>-0.077166</td>\n",
       "      <td>0.171117</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.317875</td>\n",
       "      <td>-0.391166</td>\n",
       "      <td>-0.346829</td>\n",
       "      <td>-0.101455</td>\n",
       "      <td>0.218276</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>0.184389</td>\n",
       "      <td>0.275933</td>\n",
       "      <td>0.219873</td>\n",
       "      <td>-0.199641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079862</td>\n",
       "      <td>-0.126056</td>\n",
       "      <td>0.120228</td>\n",
       "      <td>0.241789</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>-0.116866</td>\n",
       "      <td>0.137638</td>\n",
       "      <td>0.378380</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.189565</td>\n",
       "      <td>-0.228894</td>\n",
       "      <td>-0.134339</td>\n",
       "      <td>-0.100182</td>\n",
       "      <td>0.126142</td>\n",
       "      <td>0.122312</td>\n",
       "      <td>0.154340</td>\n",
       "      <td>0.137634</td>\n",
       "      <td>0.436666</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053833</td>\n",
       "      <td>0.142990</td>\n",
       "      <td>0.144225</td>\n",
       "      <td>-0.100617</td>\n",
       "      <td>0.098143</td>\n",
       "      <td>-0.059571</td>\n",
       "      <td>-0.064255</td>\n",
       "      <td>0.409050</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.427210 -0.320270 -0.282973 -0.141028  0.262942  0.065654  0.073298   \n",
       "1 -0.317875 -0.391166 -0.346829 -0.101455  0.218276 -0.002775  0.184389   \n",
       "2 -0.189565 -0.228894 -0.134339 -0.100182  0.126142  0.122312  0.154340   \n",
       "\n",
       "          7         8         9  ...        92        93        94        95  \\\n",
       "0  0.137498  0.296130 -0.075196  ... -0.029153  0.157873  0.154806  0.033090   \n",
       "1  0.275933  0.219873 -0.199641  ...  0.079862 -0.126056  0.120228  0.241789   \n",
       "2  0.137634  0.436666  0.000482  ...  0.053833  0.142990  0.144225 -0.100617   \n",
       "\n",
       "         96        97        98        99            ID  diagnosis  \n",
       "0  0.054093 -0.021883 -0.077166  0.171117  sub-87964717        SMC  \n",
       "1  0.017197 -0.116866  0.137638  0.378380  sub-87964717        SMC  \n",
       "2  0.098143 -0.059571 -0.064255  0.409050  sub-87964717        SMC  \n",
       "\n",
       "[3 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick SVM model\n",
      "[[56  9 14 14 15]\n",
      " [ 4 31 17 36 20]\n",
      " [16 12 24 38 18]\n",
      " [ 5 23 21 35 24]\n",
      " [ 0  5 29 20 54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADHD       0.69      0.52      0.59       108\n",
      "     HEALTHY       0.39      0.29      0.33       108\n",
      "         MDD       0.23      0.22      0.23       108\n",
      "         OCD       0.24      0.32      0.28       108\n",
      "         SMC       0.41      0.50      0.45       108\n",
      "\n",
      "    accuracy                           0.37       540\n",
      "   macro avg       0.39      0.37      0.38       540\n",
      "weighted avg       0.39      0.37      0.38       540\n",
      "\n",
      "0.3756998493301762\n",
      "\n",
      "quick random forest model\n",
      "[[63  9 13 13 10]\n",
      " [18 31 21 22 16]\n",
      " [28 25 14 23 18]\n",
      " [11 28 20 23 26]\n",
      " [ 4 21 23 18 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADHD       0.51      0.58      0.54       108\n",
      "     HEALTHY       0.27      0.29      0.28       108\n",
      "         MDD       0.15      0.13      0.14       108\n",
      "         OCD       0.23      0.21      0.22       108\n",
      "         SMC       0.38      0.39      0.38       108\n",
      "\n",
      "    accuracy                           0.32       540\n",
      "   macro avg       0.31      0.32      0.31       540\n",
      "weighted avg       0.31      0.32      0.31       540\n",
      "\n",
      "0.313425329836697\n"
     ]
    }
   ],
   "source": [
    "# best model checkpoint\n",
    "get_ssl_features('contrastive_loss_default_pretext_model', dataset, df_sample, eval=True, to_disk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_df.shape = (2688, 102)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128607</td>\n",
       "      <td>0.138197</td>\n",
       "      <td>-2.235987</td>\n",
       "      <td>-1.701625</td>\n",
       "      <td>3.545807</td>\n",
       "      <td>-1.874852</td>\n",
       "      <td>2.633586</td>\n",
       "      <td>-1.813814</td>\n",
       "      <td>-0.959881</td>\n",
       "      <td>-2.024573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>2.923007</td>\n",
       "      <td>3.074398</td>\n",
       "      <td>0.924193</td>\n",
       "      <td>-0.835261</td>\n",
       "      <td>-0.142691</td>\n",
       "      <td>-1.170481</td>\n",
       "      <td>-1.667304</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.118486</td>\n",
       "      <td>2.918775</td>\n",
       "      <td>-3.907192</td>\n",
       "      <td>-0.223409</td>\n",
       "      <td>4.939961</td>\n",
       "      <td>-0.680720</td>\n",
       "      <td>2.935375</td>\n",
       "      <td>-1.185846</td>\n",
       "      <td>1.424726</td>\n",
       "      <td>-0.685542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466219</td>\n",
       "      <td>-0.417178</td>\n",
       "      <td>-0.076883</td>\n",
       "      <td>1.810046</td>\n",
       "      <td>-1.779487</td>\n",
       "      <td>-0.976218</td>\n",
       "      <td>-1.046167</td>\n",
       "      <td>2.468539</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380765</td>\n",
       "      <td>-0.459981</td>\n",
       "      <td>-0.608639</td>\n",
       "      <td>-0.373267</td>\n",
       "      <td>2.232232</td>\n",
       "      <td>1.592137</td>\n",
       "      <td>0.924958</td>\n",
       "      <td>-3.015853</td>\n",
       "      <td>0.509243</td>\n",
       "      <td>-1.728560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339910</td>\n",
       "      <td>3.535902</td>\n",
       "      <td>2.091701</td>\n",
       "      <td>0.755230</td>\n",
       "      <td>-1.798280</td>\n",
       "      <td>-1.933364</td>\n",
       "      <td>-0.464456</td>\n",
       "      <td>-0.927624</td>\n",
       "      <td>sub-87964717</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.128607  0.138197 -2.235987 -1.701625  3.545807 -1.874852  2.633586   \n",
       "1 -1.118486  2.918775 -3.907192 -0.223409  4.939961 -0.680720  2.935375   \n",
       "2  0.380765 -0.459981 -0.608639 -0.373267  2.232232  1.592137  0.924958   \n",
       "\n",
       "          7         8         9  ...        92        93        94        95  \\\n",
       "0 -1.813814 -0.959881 -2.024573  ...  0.010959  2.923007  3.074398  0.924193   \n",
       "1 -1.185846  1.424726 -0.685542  ...  0.466219 -0.417178 -0.076883  1.810046   \n",
       "2 -3.015853  0.509243 -1.728560  ...  0.339910  3.535902  2.091701  0.755230   \n",
       "\n",
       "         96        97        98        99            ID  diagnosis  \n",
       "0 -0.835261 -0.142691 -1.170481 -1.667304  sub-87964717        SMC  \n",
       "1 -1.779487 -0.976218 -1.046167  2.468539  sub-87964717        SMC  \n",
       "2 -1.798280 -1.933364 -0.464456 -0.927624  sub-87964717        SMC  \n",
       "\n",
       "[3 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick SVM model\n",
      "[[58 13  3  5 29]\n",
      " [ 5 30 26 11 36]\n",
      " [ 6 24 14  7 57]\n",
      " [ 2 22 14 15 55]\n",
      " [ 1 14  7  8 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADHD       0.81      0.54      0.64       108\n",
      "     HEALTHY       0.29      0.28      0.28       108\n",
      "         MDD       0.22      0.13      0.16       108\n",
      "         OCD       0.33      0.14      0.19       108\n",
      "         SMC       0.31      0.72      0.43       108\n",
      "\n",
      "    accuracy                           0.36       540\n",
      "   macro avg       0.39      0.36      0.34       540\n",
      "weighted avg       0.39      0.36      0.34       540\n",
      "\n",
      "0.34323051852264397\n",
      "\n",
      "quick random forest model\n",
      "[[59 15 13 11 10]\n",
      " [11 36 24 17 20]\n",
      " [10 30 23 17 28]\n",
      " [ 9 22 23 23 31]\n",
      " [ 4 20 21 24 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADHD       0.63      0.55      0.59       108\n",
      "     HEALTHY       0.29      0.33      0.31       108\n",
      "         MDD       0.22      0.21      0.22       108\n",
      "         OCD       0.25      0.21      0.23       108\n",
      "         SMC       0.30      0.36      0.33       108\n",
      "\n",
      "    accuracy                           0.33       540\n",
      "   macro avg       0.34      0.33      0.34       540\n",
      "weighted avg       0.34      0.33      0.34       540\n",
      "\n",
      "0.33524851899139396\n"
     ]
    }
   ],
   "source": [
    "# overtrained model\n",
    "get_ssl_features('overtrained_contrastive_loss_default_pretext_model', dataset, df_sample, eval=True, to_disk=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
