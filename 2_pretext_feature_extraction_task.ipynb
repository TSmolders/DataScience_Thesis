{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM: Extract features on labeled data using the pretrained EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# prevent extensive logging\n",
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['EEGNet1.block1.0.weight', 'EEGNet1.block1.1.weight', 'EEGNet1.block1.1.bias', 'EEGNet1.block1.1.running_mean', 'EEGNet1.block1.1.running_var', 'EEGNet1.block1.1.num_batches_tracked', 'EEGNet1.block1.2.weight', 'EEGNet1.block1.3.weight', 'EEGNet1.block1.3.bias', 'EEGNet1.block1.3.running_mean', 'EEGNet1.block1.3.running_var', 'EEGNet1.block1.3.num_batches_tracked', 'EEGNet1.block2.0.weight', 'EEGNet1.block2.1.weight', 'EEGNet1.block2.2.weight', 'EEGNet1.block2.2.bias', 'EEGNet1.block2.2.running_mean', 'EEGNet1.block2.2.running_var', 'EEGNet1.block2.2.num_batches_tracked', 'EEGNet1.lin.weight', 'EEGNet2.block1.0.weight', 'EEGNet2.block1.1.weight', 'EEGNet2.block1.1.bias', 'EEGNet2.block1.1.running_mean', 'EEGNet2.block1.1.running_var', 'EEGNet2.block1.1.num_batches_tracked', 'EEGNet2.block1.2.weight', 'EEGNet2.block1.3.weight', 'EEGNet2.block1.3.bias', 'EEGNet2.block1.3.running_mean', 'EEGNet2.block1.3.running_var', 'EEGNet2.block1.3.num_batches_tracked', 'EEGNet2.block2.0.weight', 'EEGNet2.block2.1.weight', 'EEGNet2.block2.2.weight', 'EEGNet2.block2.2.bias', 'EEGNet2.block2.2.running_mean', 'EEGNet2.block2.2.running_var', 'EEGNet2.block2.2.num_batches_tracked', 'EEGNet2.lin.weight', 'linear.weight', 'linear.bias'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the pretrained weights\n",
    "pretrained_dict = torch.load('pretext_model_weights.pt')\n",
    "pretrained_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEGNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Conv2d with max norm constraint\n",
    "class Conv2dWithConstraint(nn.Conv2d):\n",
    "    def __init__(self, *args, max_norm: int = 1, **kwargs):\n",
    "        self.max_norm = max_norm\n",
    "        super(Conv2dWithConstraint, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.weight.data = torch.renorm(self.weight.data, p=2, dim=0, maxnorm=self.max_norm)\n",
    "        return super(Conv2dWithConstraint, self).forward(x)\n",
    "    \n",
    "class EEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Code taken and adjusted from pytorch implementation of EEGNet\n",
    "    url: https://github.com/torcheeg/torcheeg/blob/v1.1.0/torcheeg/models/cnn/eegnet.py#L5\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 chunk_size: int = 1244, # number of data points in each EEG chunk\n",
    "                 num_electrodes: int = 26, # number of EEG electrodes\n",
    "                 F1: int = 8, # number of filters in first convolutional layer\n",
    "                 F2: int = 16, # number of filters in second convolutional layer\n",
    "                 D: int = 2, # depth multiplier\n",
    "                 num_extracted_features: int = 100, # number of features to extract\n",
    "                 kernel_1: int = 64, # the filter size of block 1 (half of sfreq (125 Hz))\n",
    "                 kernel_2: int = 16, # the filter size of block 2 (one eight of sfreq (500 Hz))\n",
    "                 dropout: float = 0.25): # dropout rate\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.F1 = F1\n",
    "        self.F2 = F2\n",
    "        self.D = D\n",
    "        self.chunk_size = chunk_size\n",
    "        self.num_extracted_features = num_extracted_features\n",
    "        self.num_electrodes = num_electrodes\n",
    "        self.kernel_1 = kernel_1\n",
    "        self.kernel_2 = kernel_2\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, self.F1, (1, self.kernel_1), stride=1, padding=(0, self.kernel_1 // 2), bias=False),\n",
    "            nn.BatchNorm2d(self.F1, momentum=0.01, affine=True, eps=1e-3),\n",
    "            Conv2dWithConstraint(self.F1,\n",
    "                                 self.F1 * self.D, (self.num_electrodes, 1),\n",
    "                                 max_norm=1,\n",
    "                                 stride=1,\n",
    "                                 padding=(0, 0),\n",
    "                                 groups=self.F1,\n",
    "                                 bias=False), nn.BatchNorm2d(self.F1 * self.D, momentum=0.01, affine=True, eps=1e-3),\n",
    "            nn.ELU(), nn.AvgPool2d((1, 4), stride=4), nn.Dropout(p=dropout))\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(self.F1 * self.D,\n",
    "                      self.F1 * self.D, (1, self.kernel_2),\n",
    "                      stride=1,\n",
    "                      padding=(0, self.kernel_2 // 2),\n",
    "                      bias=False,\n",
    "                      groups=self.F1 * self.D),\n",
    "            nn.Conv2d(self.F1 * self.D, self.F2, 1, padding=(0, 0), groups=1, bias=False, stride=1),\n",
    "            nn.BatchNorm2d(self.F2, momentum=0.01, affine=True, eps=1e-3), nn.ELU(), nn.AvgPool2d((1, 8), stride=8),\n",
    "            nn.Dropout(p=dropout))\n",
    "\n",
    "        self.lin = nn.Linear(self.feature_dim(), num_extracted_features, bias=False)\n",
    "\n",
    "\n",
    "    def feature_dim(self):\n",
    "        # function to calculate the number of features after the convolutional blocks\n",
    "        with torch.no_grad():\n",
    "            mock_eeg = torch.zeros(1, 1, self.num_electrodes, self.chunk_size)\n",
    "\n",
    "            mock_eeg = self.block1(mock_eeg)\n",
    "            mock_eeg = self.block2(mock_eeg)\n",
    "\n",
    "        return self.F2 * mock_eeg.shape[3]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfering pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All weights match successfully.\n"
     ]
    }
   ],
   "source": [
    "pretrained_EEGNet = EEGNet()\n",
    "model_dict = pretrained_EEGNet.state_dict()\n",
    "\n",
    "processed_dict = {}\n",
    "for k in pretrained_dict.keys(): \n",
    "    decomposed_key = k.split(\".\")\n",
    "    if(\"EEGNet1\" in decomposed_key):\n",
    "        pretrained_key = \".\".join(decomposed_key[1:])\n",
    "        processed_dict[pretrained_key] = pretrained_dict[k]\n",
    "\n",
    "pretrained_EEGNet.load_state_dict(processed_dict, strict=True)\n",
    "\n",
    "# Assert that the weights are the same\n",
    "for key in processed_dict:\n",
    "    assert torch.equal(pretrained_EEGNet.state_dict()[key], processed_dict[key]), f\"Mismatch found in key: {key}\"\n",
    "\n",
    "print(\"All weights match successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load participant data of labeled sample\n",
    "These dataframes have been filtered and stored in a previous project. See https://github.com/TSmolders/Internship_EEG for original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 12)\n",
      "diagnosis\n",
      "ADHD       45\n",
      "HEALTHY    45\n",
      "MDD        45\n",
      "OCD        45\n",
      "SMC        45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_participants = pd.read_pickle(r'D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TDBRAIN_participants_V2_data\\df_participants.pkl')\n",
    "sample_df = pd.read_pickle(r'D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TD-BRAIN_extracted_features\\df_selected_stat_features.pkl')\n",
    "sample_ids = sample_df['ID'].unique() # obtain unique IDs from subsampled dataframe containing epoched features\n",
    "df_sample = df_participants[df_participants['participants_ID'].isin(sample_ids)] # filter participants dataframe to only include subsampled IDs\n",
    "df_sample = df_sample[df_sample['sessID'] == 1] # filter first session\n",
    "print(df_sample.shape)\n",
    "print(df_sample['diagnosis'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_ID</th>\n",
       "      <th>DISC/REP</th>\n",
       "      <th>indication</th>\n",
       "      <th>formal_status</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>sessID</th>\n",
       "      <th>nrSessions</th>\n",
       "      <th>EC</th>\n",
       "      <th>EO</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>sub-88055301</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>HEALTHY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>HEALTHY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>sub-88048193</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>OCD</td>\n",
       "      <td>OCD</td>\n",
       "      <td>OCD</td>\n",
       "      <td>53.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>OCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>sub-88017633</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>sub-88053273</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>ADHD_NF</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>sub-88075593</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     participants_ID   DISC/REP indication formal_status  Dataset    age  \\\n",
       "1065    sub-88055301  DISCOVERY    HEALTHY       HEALTHY      NaN  40.02   \n",
       "972     sub-88048193  DISCOVERY        OCD           OCD      OCD  53.25   \n",
       "557     sub-88017633  DISCOVERY       ADHD       UNKNOWN      NaN   7.33   \n",
       "1038    sub-88053273  DISCOVERY       ADHD          ADHD  ADHD_NF   9.45   \n",
       "1298    sub-88075593  DISCOVERY       ADHD       UNKNOWN      NaN  35.38   \n",
       "\n",
       "      gender  sessID  nrSessions    EC    EO diagnosis  \n",
       "1065       1       1           1  True  True   HEALTHY  \n",
       "972        0       1           2  True  True       OCD  \n",
       "557        1       1           1  True  True      ADHD  \n",
       "1038       1       1           1  True  True      ADHD  \n",
       "1298       1       1           1  True  True      ADHD  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features for these participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_filepath(epoch_dir, participant_ids):\n",
    "    \"\"\"\n",
    "    Function to get the filepath of the epoched EEG recording\n",
    "    :param epoch_dir: directory containing the epoched EEG recordings\n",
    "    :param ID: list of participant IDs to include\n",
    "    \"\"\"\n",
    "    filepaths = []\n",
    "    for subdir, dirs, files in os.walk(epoch_dir):\n",
    "        for file in files:\n",
    "            if any(participant_id in file for participant_id in participant_ids):\n",
    "                filepaths.append(os.path.join(subdir, file))\n",
    "    return filepaths\n",
    "\n",
    "class EpochDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, participant_ids, epoch_dir):\n",
    "        self.filepaths = get_filepath(epoch_dir, participant_ids)\n",
    "        self.participant_ids = participant_ids\n",
    "        self.epochs = []\n",
    "        self.participant_ids = []\n",
    "        self._load_data()\n",
    "        print(f\"Number of epochs: {self.epochs.shape[0]}\")\n",
    "        print(f\"Number of participants: {len(self.participant_ids)}\")\n",
    "\n",
    "    def _load_data(self):\n",
    "        all_epochs = []\n",
    "        for filepath in self.filepaths:\n",
    "            epochs = torch.load(filepath)\n",
    "            # get participant ID from filepath to make sure the participant ID is correct\n",
    "            participant_id = filepath.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "            all_epochs.append(epochs)\n",
    "            self.participant_ids.extend([participant_id]*epochs.shape[0])\n",
    "        self.epochs = np.concatenate(all_epochs, axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.epochs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        epoch = self.epochs[idx]\n",
    "        participant_id = self.participant_ids[idx]\n",
    "        return torch.tensor(epoch, dtype=torch.float32), participant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 2688\n",
      "Number of participants: 2688\n",
      "2688\n",
      "torch.Size([26, 1244])\n",
      "sub-87964717\n",
      "sub-87964717\n"
     ]
    }
   ],
   "source": [
    "participant_ids = df_sample['participants_ID'].tolist()\n",
    "dataset = EpochDataset(participant_ids, r\"D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TDBRAIN-dataset-derivatives\\thesis_epoched_data\\EC\")\n",
    "print(len(dataset))\n",
    "print(dataset[0][0].shape)\n",
    "print(dataset[0][1])\n",
    "print(dataset[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# created with help of GitHub Copilot\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "pretrained_EEGNet.eval() ## TODO: Should I set the model to evaluation mode?\n",
    "\n",
    "features_list = []\n",
    "participant_ids = []\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for batch in dataloader:\n",
    "        epoch, participant_id = batch  # Remove the batch dimension\n",
    "        epoch = epoch.unsqueeze(0)  # Add dimension\n",
    "        # print(epoch.shape)\n",
    "        features = pretrained_EEGNet(epoch)  # Extract features\n",
    "        features = features.squeeze(0)\n",
    "        features = features.numpy()\n",
    "        features_list.append(features)\n",
    "        participant_ids.append(participant_id[0])\n",
    "\n",
    "print(len(features_list))\n",
    "print(features_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the features to disk\n",
    "features_df = pd.DataFrame(features_list)\n",
    "\n",
    "# Add participant IDs to the DataFrame\n",
    "features_df['ID'] = participant_ids\n",
    "\n",
    "# Map the diagnosis values from df_sample to the DataFrame based on participant IDs\n",
    "features_df['diagnosis'] = features_df['ID'].map(df_sample.set_index('participants_ID')['diagnosis'])\n",
    "\n",
    "features_df.to_pickle(r'D:\\Documents\\Master_Data_Science\\Thesis\\thesis_code\\DataScience_Thesis\\data\\df_ssl_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>3.664361</td>\n",
       "      <td>-3.131516</td>\n",
       "      <td>1.695510</td>\n",
       "      <td>0.155439</td>\n",
       "      <td>-0.828389</td>\n",
       "      <td>-1.076838</td>\n",
       "      <td>-0.745050</td>\n",
       "      <td>1.110973</td>\n",
       "      <td>0.017292</td>\n",
       "      <td>-0.978348</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.024903</td>\n",
       "      <td>0.565701</td>\n",
       "      <td>2.176804</td>\n",
       "      <td>1.036991</td>\n",
       "      <td>1.820049</td>\n",
       "      <td>1.932001</td>\n",
       "      <td>-0.626927</td>\n",
       "      <td>-2.327834</td>\n",
       "      <td>sub-88041305</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>2.625418</td>\n",
       "      <td>-1.087079</td>\n",
       "      <td>0.747795</td>\n",
       "      <td>0.621140</td>\n",
       "      <td>-0.333993</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>-0.697683</td>\n",
       "      <td>0.583098</td>\n",
       "      <td>0.197683</td>\n",
       "      <td>-0.453607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.383320</td>\n",
       "      <td>0.201196</td>\n",
       "      <td>2.172565</td>\n",
       "      <td>-0.747482</td>\n",
       "      <td>0.811691</td>\n",
       "      <td>0.752884</td>\n",
       "      <td>-0.484254</td>\n",
       "      <td>-1.290530</td>\n",
       "      <td>sub-88059977</td>\n",
       "      <td>OCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>2.466621</td>\n",
       "      <td>2.535407</td>\n",
       "      <td>2.016782</td>\n",
       "      <td>1.503323</td>\n",
       "      <td>1.683569</td>\n",
       "      <td>-0.807519</td>\n",
       "      <td>0.955875</td>\n",
       "      <td>0.192149</td>\n",
       "      <td>3.316376</td>\n",
       "      <td>-0.926541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.247190</td>\n",
       "      <td>-1.724805</td>\n",
       "      <td>-3.091214</td>\n",
       "      <td>-1.538718</td>\n",
       "      <td>-2.412516</td>\n",
       "      <td>-0.334150</td>\n",
       "      <td>1.119130</td>\n",
       "      <td>-0.960216</td>\n",
       "      <td>sub-88056021</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>-0.521252</td>\n",
       "      <td>0.191501</td>\n",
       "      <td>0.153712</td>\n",
       "      <td>-0.137607</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>-0.106556</td>\n",
       "      <td>0.205999</td>\n",
       "      <td>-0.331544</td>\n",
       "      <td>0.819242</td>\n",
       "      <td>-0.566306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219668</td>\n",
       "      <td>-1.222554</td>\n",
       "      <td>-0.980601</td>\n",
       "      <td>0.792679</td>\n",
       "      <td>-1.333334</td>\n",
       "      <td>0.213945</td>\n",
       "      <td>0.695682</td>\n",
       "      <td>1.165446</td>\n",
       "      <td>sub-88075053</td>\n",
       "      <td>HEALTHY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>-0.345381</td>\n",
       "      <td>1.803453</td>\n",
       "      <td>-0.258202</td>\n",
       "      <td>1.175605</td>\n",
       "      <td>-2.197935</td>\n",
       "      <td>1.675406</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>2.722747</td>\n",
       "      <td>0.556865</td>\n",
       "      <td>-1.083907</td>\n",
       "      <td>...</td>\n",
       "      <td>4.931505</td>\n",
       "      <td>-2.216218</td>\n",
       "      <td>-0.089509</td>\n",
       "      <td>-2.244158</td>\n",
       "      <td>-0.412924</td>\n",
       "      <td>-0.674755</td>\n",
       "      <td>-1.632735</td>\n",
       "      <td>0.326206</td>\n",
       "      <td>sub-88074917</td>\n",
       "      <td>OCD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1397  3.664361 -3.131516  1.695510  0.155439 -0.828389 -1.076838 -0.745050   \n",
       "2102  2.625418 -1.087079  0.747795  0.621140 -0.333993  0.171692 -0.697683   \n",
       "1932  2.466621  2.535407  2.016782  1.503323  1.683569 -0.807519  0.955875   \n",
       "2625 -0.521252  0.191501  0.153712 -0.137607  0.068807 -0.106556  0.205999   \n",
       "2604 -0.345381  1.803453 -0.258202  1.175605 -2.197935  1.675406  0.006974   \n",
       "\n",
       "             7         8         9  ...        92        93        94  \\\n",
       "1397  1.110973  0.017292 -0.978348  ... -3.024903  0.565701  2.176804   \n",
       "2102  0.583098  0.197683 -0.453607  ... -0.383320  0.201196  2.172565   \n",
       "1932  0.192149  3.316376 -0.926541  ...  1.247190 -1.724805 -3.091214   \n",
       "2625 -0.331544  0.819242 -0.566306  ...  0.219668 -1.222554 -0.980601   \n",
       "2604  2.722747  0.556865 -1.083907  ...  4.931505 -2.216218 -0.089509   \n",
       "\n",
       "            95        96        97        98        99            ID  \\\n",
       "1397  1.036991  1.820049  1.932001 -0.626927 -2.327834  sub-88041305   \n",
       "2102 -0.747482  0.811691  0.752884 -0.484254 -1.290530  sub-88059977   \n",
       "1932 -1.538718 -2.412516 -0.334150  1.119130 -0.960216  sub-88056021   \n",
       "2625  0.792679 -1.333334  0.213945  0.695682  1.165446  sub-88075053   \n",
       "2604 -2.244158 -0.412924 -0.674755 -1.632735  0.326206  sub-88074917   \n",
       "\n",
       "      diagnosis  \n",
       "1397       ADHD  \n",
       "2102        OCD  \n",
       "1932       ADHD  \n",
       "2625    HEALTHY  \n",
       "2604        OCD  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34 20 15 19 18]\n",
      " [20 14 15 22 37]\n",
      " [ 8 18 23 24 35]\n",
      " [14 18 18 23 35]\n",
      " [ 8 20 14 16 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADHD       0.40      0.32      0.36       106\n",
      "     HEALTHY       0.16      0.13      0.14       108\n",
      "         MDD       0.27      0.21      0.24       108\n",
      "         OCD       0.22      0.21      0.22       108\n",
      "         SMC       0.29      0.46      0.35       108\n",
      "\n",
      "    accuracy                           0.27       538\n",
      "   macro avg       0.27      0.27      0.26       538\n",
      "weighted avg       0.27      0.27      0.26       538\n",
      "\n",
      "0.2615977739405999\n"
     ]
    }
   ],
   "source": [
    "# quick svm model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "X = features_df.drop(['ID', 'diagnosis'], axis=1)\n",
    "y = features_df['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# extracting features with randomly initialized EEGNet\n",
    "random_EEGNet = EEGNet()\n",
    "random_features_list = []\n",
    "random_participant_ids = []\n",
    "# created with help of GitHub Copilot\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "random_EEGNet.eval() ## TODO: Should I set the model to evaluation mode?\n",
    "\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for batch in dataloader:\n",
    "        epoch, participant_id = batch  # Remove the batch dimension\n",
    "        epoch = epoch.unsqueeze(0)  # Add dimension\n",
    "        # print(epoch.shape)\n",
    "        features = random_EEGNet(epoch)  # Extract features\n",
    "        features = features.squeeze(0)\n",
    "        features = features.numpy()\n",
    "        random_features_list.append(features)\n",
    "        random_participant_ids.append(participant_id[0])\n",
    "\n",
    "print(len(random_features_list))\n",
    "print(random_features_list[0].shape)\n",
    "\n",
    "# store the features to disk\n",
    "random_features_df = pd.DataFrame(random_features_list)\n",
    "# Add participant IDs to the DataFrame\n",
    "random_features_df['ID'] = random_participant_ids\n",
    "# Map the diagnosis values from df_sample to the DataFrame based on participant IDs\n",
    "random_features_df['diagnosis'] = random_features_df['ID'].map(df_sample.set_index('participants_ID')['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44 10  8 18 26]\n",
      " [ 3 24 14 36 31]\n",
      " [ 8 13 16 28 43]\n",
      " [ 3 14 15 33 43]\n",
      " [ 0  8 16 22 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADHD       0.76      0.42      0.54       106\n",
      "     HEALTHY       0.35      0.22      0.27       108\n",
      "         MDD       0.23      0.15      0.18       108\n",
      "         OCD       0.24      0.31      0.27       108\n",
      "         SMC       0.30      0.57      0.40       108\n",
      "\n",
      "    accuracy                           0.33       538\n",
      "   macro avg       0.38      0.33      0.33       538\n",
      "weighted avg       0.37      0.33      0.33       538\n",
      "\n",
      "0.3308233312541893\n"
     ]
    }
   ],
   "source": [
    "X = random_features_df.drop(['ID', 'diagnosis'], axis=1)\n",
    "y = random_features_df['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
